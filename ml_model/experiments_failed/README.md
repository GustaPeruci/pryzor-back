# üî¨ Experimentos de ML - Modelos Descartados

Esta pasta cont√©m modelos experimentais que **falharam** durante o processo de desenvolvimento.

Mantemos esses arquivos para **fins de documenta√ß√£o acad√™mica** (TCC) e an√°lise hist√≥rica.

‚ö†Ô∏è **IMPORTANTE:** Esses modelos **N√ÉO devem ser usados em produ√ß√£o**.

---

## üì¶ `discount_predictor_v2_1.pkl`

**Status:** ‚ùå REJEITADO  
**Data:** Outubro 2025  
**Motivo:** Performance significativamente inferior ao v2.0

### O que foi tentado

Expandir o modelo v2.0 (8 features) para v2.1 (11 features) adicionando 3 features de dura√ß√£o de promo√ß√£o:

1. **discount_consecutive_days** - Quantos dias o jogo est√° em promo√ß√£o consecutivamente
2. **discount_progress_ratio** - Progresso da promo√ß√£o (0 a 2, onde 1 = dura√ß√£o mediana)
3. **discount_likely_ending** - Booleano indicando se a promo√ß√£o est√° perto do fim (>50% da dura√ß√£o)

### Motiva√ß√£o

- Valida√ß√£o em 1.000 jogos revelou que v2.0 tinha **apenas 5.4% de acerto** em casos com desconto ativo
- 53 de 76 erros totais eram em jogos que j√° estavam em promo√ß√£o
- Hip√≥tese: Features de dura√ß√£o ajudariam a detectar quando uma promo√ß√£o est√° terminando

### Metodologia

```python
# Feature engineering de dura√ß√£o
df['discount_consecutive_days'] = df.groupby(['appid', 'discount_group']).cumcount() + 1
df['discount_progress_ratio'] = df['discount_consecutive_days'] / df['median_discount_duration']
df['discount_likely_ending'] = (df['discount_progress_ratio'] >= 0.5) & (df['has_discount'] == 1)

# Mesmo RandomForest do v2.0
RandomForestClassifier(
    n_estimators=200,
    max_depth=15,
    class_weight='balanced',
    random_state=42
)
```

### Resultados (Set de Teste)

| M√©trica | v2.0 | v2.1 | Varia√ß√£o | Status |
|---------|------|------|----------|--------|
| **Precision** | 90.46% | 25.67% | **-64.79%** | üìâ CR√çTICO |
| **F1-Score** | 74.34% | 38.11% | **-36.23%** | üìâ DEVASTADOR |
| **Recall** | 63.09% | 73.97% | +10.88% | üìà Aumentou |
| **ROC-AUC** | 79.45% | 73.71% | -5.74% | üìâ Piorou |

### Confusion Matrix (v2.1)

```
Real/Predicted     N√£o Desconto    Tem Desconto
N√£o Desconto:         110,139         56,636  ‚Üê 56K FALSE POSITIVES!
Tem Desconto:           6,883         19,558
```

### An√°lise de Feature Importance

As features de dura√ß√£o **eram importantes**:
- `discount_consecutive_days`: **3¬∫ lugar** (10.55%)
- `discount_progress_ratio`: 5¬∫ lugar (6.76%)
- `discount_likely_ending`: 10¬∫ lugar (1.19%)

**Mas causaram desbalanceamento severo.**

### O que deu errado?

1. **Modelo "ansioso"**: As features de dura√ß√£o fizeram o modelo prever desconto em quase tudo
2. **Falsos positivos**: 56.636 casos preveram desconto quando n√£o havia (vs precision 90% do v2.0)
3. **Overfitting em padr√µes**: Modelo aprendeu "tem desconto h√° X dias ‚Üí vai continuar sempre"
4. **Trade-off ruim**: Recall aumentou (+10%), mas precision destru√≠da (-65%)

Para um **sistema de recomenda√ß√£o**, precision baixa (25%) √© **inaceit√°vel** - ningu√©m confia em alertas falsos.

### Li√ß√µes Aprendidas

‚úÖ **Features de dura√ß√£o S√ÉO importantes** (ranking alto)  
‚ùå **Mas causam overfitting quando adicionadas naivamente**  
‚úÖ **Modelo simples (v2.0) generaliza melhor**  
‚ùå **Complexity ‚â† Better Performance**  
‚úÖ **Precision > Recall** para sistemas de recomenda√ß√£o

### Decis√£o Final

**Reverter para v2.0**. 

- v2.0 tem 90% precision (confi√°vel)
- v2.1 tem 26% precision (spam de false positives)
- Usu√°rios preferem **menos alertas corretos** do que **muitos alertas errados**

---

## üéì Valor Acad√™mico (TCC)

Este experimento demonstra:

1. **M√©todo cient√≠fico aplicado**: Hip√≥tese ‚Üí Implementa√ß√£o ‚Üí Teste ‚Üí Conclus√£o
2. **An√°lise de features**: Importance ‚â† Usefulness
3. **Trade-offs em ML**: Precision vs Recall, Simplicidade vs Complexidade
4. **Valida√ß√£o rigorosa**: M√©tricas guiam decis√µes (n√£o intui√ß√£o)
5. **Honestidade cient√≠fica**: Nem toda tentativa de melhoria funciona

**Resultado negativo √© resultado v√°lido** - documenta o que N√ÉO funciona e por qu√™.

---

## üìä Dados de Treinamento

- **Dataset**: 725.268 registros de pre√ßos (2019-2020)
- **Jogos**: 1.505 paid games
- **Train/Test Split**: Temporal (2020-04-01)
  - Train: 529.029 registros (pr√©-2020)
  - Test: 193.216 registros (p√≥s-2020)
- **Target**: desconto >= 20% nos pr√≥ximos 30 dias
- **Class balance**: ~15% positivos (balanced com weights)

---

## üîó Refer√™ncias

- Script de treinamento: `scripts/03_train_model_v2_1.py`
- Modelo em produ√ß√£o: `ml_model/discount_predictor.pkl` (v2.0)
- Valida√ß√£o real: `scripts/validate_model_v2.py` (1.000 jogos testados)
- Documenta√ß√£o completa: `README.md` (se√ß√£o "Hist√≥rico de Evolu√ß√£o do Modelo")

---

**√öltima atualiza√ß√£o:** Outubro 2025  
**Autor:** Gustavo Peruci  
**Projeto:** Pryzor - TCC Engenharia de Software
