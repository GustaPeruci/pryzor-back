"""
Script para treinar modelo baseline de predi√ß√£o de descontos.

Objetivo: Prever se um jogo ter√° desconto >20% nos pr√≥ximos 30 dias.
Tipo: Classifica√ß√£o bin√°ria (0 = n√£o, 1 = sim)

Este script:
1. Carrega dataset com target bin√°rio (data_with_binary_target.csv)
2. Seleciona features SEM vazamento de alvo
3. Treina RandomForestClassifier com VALIDA√á√ÉO TEMPORAL (n√£o aleat√≥ria)
4. Calcula m√©tricas: F1-Score, Precision, Recall, Accuracy
5. Salva modelo treinado (.pkl)

IMPORTANTE: Usa split temporal (antes/depois de 2020-04-01) para evitar
vazamento temporal comum em s√©ries temporais.

Meta: F1-Score ‚â• 0.50 (com valida√ß√£o temporal correta)

Autor: Pryzor Team
Data: 21/10/2025
Vers√£o: 2.0 (corrigido split temporal)
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import pickle
import warnings

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    f1_score,
    precision_score,
    recall_score,
    accuracy_score,
    roc_auc_score
)

warnings.filterwarnings('ignore')


def load_dataset(file_path: Path) -> pd.DataFrame:
    """
    Carrega dataset com target bin√°rio.
    
    Args:
        file_path: Caminho para data_with_binary_target.csv
    
    Returns:
        DataFrame com todas as colunas
    """
    print(f"üìñ Carregando dataset de {file_path}...")
    df = pd.read_csv(file_path)
    print(f"‚úÖ {len(df):,} registros carregados")
    print(f"üìä Colunas: {list(df.columns)}")
    print()
    return df


def prepare_features(df: pd.DataFrame) -> tuple:
    """
    Prepara features e target para treinamento.
    
    IMPORTANTE: N√ÉO usar features que causem vazamento de alvo:
    - ‚ùå avg_final_price (derivado do target)
    - ‚ùå price_range (derivado do target)
    - ‚ùå is_premium, is_budget (derivados do target)
    
    Features permitidas:
    - ‚úÖ Temporais: month, day_of_week, is_weekend, quarter, is_summer_sale, is_winter_sale
    - ‚úÖ Pre√ßo atual: final_price (pre√ßo do dia atual, n√£o m√©dia hist√≥rica)
    - ‚úÖ Desconto atual: discount_percent (desconto do dia atual)
    
    Args:
        df: DataFrame original
    
    Returns:
        X (features), y (target), feature_names (lista de nomes)
    """
    print("üîß PREPARANDO FEATURES")
    print("-" * 80)
    
    # Features selecionadas (SEM vazamento de alvo)
    feature_columns = [
        # Temporais (sazonalidade √© importante!)
        'month',
        'day_of_week',
        'is_weekend',
        'quarter',
        'is_summer_sale',
        'is_winter_sale',
        
        # Valores do dia atual (n√£o m√©dias hist√≥ricas)
        'final_price',
        'discount_percent',
    ]
    
    # Verificar se todas as features existem
    missing_features = [col for col in feature_columns if col not in df.columns]
    if missing_features:
        raise ValueError(f"Features faltando no dataset: {missing_features}")
    
    # Remover linhas com valores nulos
    df_clean = df.dropna(subset=feature_columns + ['will_have_discount'])
    
    print(f"üìä Features selecionadas ({len(feature_columns)}):")
    for i, feat in enumerate(feature_columns, 1):
        print(f"   {i:2d}. {feat}")
    print()
    
    print(f"üßπ Linhas removidas (valores nulos): {len(df) - len(df_clean):,}")
    print(f"‚úÖ Linhas v√°lidas: {len(df_clean):,}")
    print()
    
    # Separar features e target
    X = df_clean[feature_columns].values
    y = df_clean['will_have_discount'].values
    
    print(f"üìê Shape de X: {X.shape}")
    print(f"üìê Shape de y: {y.shape}")
    print()
    
    # Estat√≠sticas do target
    unique, counts = np.unique(y, return_counts=True)
    print("üìä DISTRIBUI√á√ÉO DO TARGET:")
    print("-" * 40)
    for label, count in zip(unique, counts):
        pct = (count / len(y)) * 100
        label_name = "N√£o ter√° desconto" if label == 0 else "Ter√° desconto >20%"
        print(f"   Classe {label} ({label_name}): {count:>8,} ({pct:>5.2f}%)")
    print()
    
    return X, y, feature_columns


def train_model(X_train, y_train, random_state=42):
    """
    Treina RandomForestClassifier.
    
    Hiperpar√¢metros escolhidos:
    - n_estimators=100: N√∫mero de √°rvores (mais = melhor, mas mais lento)
    - max_depth=15: Profundidade m√°xima (evita overfitting)
    - min_samples_split=20: M√≠nimo de amostras para split
    - min_samples_leaf=10: M√≠nimo de amostras em folha
    - class_weight='balanced': Balanceia classes automaticamente
    
    Args:
        X_train: Features de treino
        y_train: Target de treino
        random_state: Seed para reprodutibilidade
    
    Returns:
        Modelo treinado
    """
    print("üå≤ TREINANDO RANDOM FOREST")
    print("-" * 80)
    
    # Configurar modelo
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=15,
        min_samples_split=20,
        min_samples_leaf=10,
        class_weight='balanced',
        random_state=random_state,
        n_jobs=-1,  # Usar todos os cores
        verbose=0
    )
    
    print("‚öôÔ∏è  Hiperpar√¢metros:")
    print(f"   - n_estimators: 100")
    print(f"   - max_depth: 15")
    print(f"   - min_samples_split: 20")
    print(f"   - min_samples_leaf: 10")
    print(f"   - class_weight: balanced")
    print()
    
    print("üèãÔ∏è  Treinando modelo...")
    start_time = datetime.now()
    
    model.fit(X_train, y_train)
    
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    print(f"‚úÖ Modelo treinado em {duration:.2f} segundos")
    print()
    
    return model


def evaluate_model(model, X_test, y_test, feature_names):
    """
    Avalia modelo no conjunto de teste.
    
    M√©tricas calculadas:
    - Accuracy: % de acertos totais
    - Precision: De todos os "sim" previstos, quantos eram corretos?
    - Recall: De todos os "sim" reais, quantos foram detectados?
    - F1-Score: M√©dia harm√¥nica entre Precision e Recall (m√©trica principal)
    - ROC-AUC: √Årea sob a curva ROC
    
    Args:
        model: Modelo treinado
        X_test: Features de teste
        y_test: Target de teste
        feature_names: Nomes das features
    
    Returns:
        Dict com m√©tricas
    """
    print("üìä AVALIA√á√ÉO NO CONJUNTO DE TESTE")
    print("=" * 80)
    
    # Predi√ß√µes
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    # Calcular m√©tricas
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    
    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    
    # Exibir resultados
    print()
    print("üéØ M√âTRICAS PRINCIPAIS")
    print("-" * 80)
    print(f"   Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"   Precision: {precision:.4f} ({precision*100:.2f}%)")
    print(f"   Recall:    {recall:.4f} ({recall*100:.2f}%)")
    print(f"   F1-Score:  {f1:.4f} ({f1*100:.2f}%) ‚≠ê")
    print(f"   ROC-AUC:   {roc_auc:.4f}")
    print()
    
    # Matriz de confus√£o
    print("üî¢ MATRIZ DE CONFUS√ÉO")
    print("-" * 80)
    print(f"   True Negatives  (TN): {tn:>8,}  (predito: n√£o, real: n√£o)")
    print(f"   False Positives (FP): {fp:>8,}  (predito: sim, real: n√£o)")
    print(f"   False Negatives (FN): {fn:>8,}  (predito: n√£o, real: sim)")
    print(f"   True Positives  (TP): {tp:>8,}  (predito: sim, real: sim)")
    print()
    
    # Relat√≥rio detalhado
    print("üìã RELAT√ìRIO DE CLASSIFICA√á√ÉO")
    print("-" * 80)
    print(classification_report(
        y_test, y_pred,
        target_names=['N√£o ter√° desconto', 'Ter√° desconto'],
        digits=4
    ))
    
    # Feature Importance
    print("üîç IMPORT√ÇNCIA DAS FEATURES (Top 10)")
    print("-" * 80)
    feature_importances = pd.DataFrame({
        'feature': feature_names,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    for idx, row in feature_importances.head(10).iterrows():
        print(f"   {row['feature']:20s}: {row['importance']:.4f}")
    print()
    
    # Retornar m√©tricas
    metrics = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'roc_auc': roc_auc,
        'confusion_matrix': cm,
        'feature_importances': feature_importances
    }
    
    return metrics


def save_model(model, feature_names, metrics, output_path: Path):
    """
    Salva modelo treinado e metadados.
    
    Args:
        model: Modelo treinado
        feature_names: Lista de nomes das features
        metrics: Dict com m√©tricas de avalia√ß√£o
        output_path: Caminho para salvar o .pkl
    """
    print("üíæ SALVANDO MODELO")
    print("-" * 80)
    
    # Criar diret√≥rio se n√£o existir
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Empacotar modelo com metadados
    model_package = {
        'model': model,
        'feature_names': feature_names,
        'metrics': metrics,
        'trained_at': datetime.now().isoformat(),
        'model_type': 'RandomForestClassifier',
        'target': 'will_have_discount (binary)',
        'version': '2.0',
        'validation_method': 'temporal_split (cutoff: 2020-04-01)',
        'notes': 'Modelo treinado com valida√ß√£o temporal adequada para evitar vazamento de dados'
    }
    
    # Salvar
    with open(output_path, 'wb') as f:
        pickle.dump(model_package, f)
    
    file_size_mb = output_path.stat().st_size / (1024 * 1024)
    print(f"‚úÖ Modelo salvo em: {output_path}")
    print(f"üì¶ Tamanho do arquivo: {file_size_mb:.2f} MB")
    print()


def main():
    """Fun√ß√£o principal para treinar modelo baseline."""
    
    print("=" * 80)
    print("TREINAMENTO DE MODELO BASELINE - Pryzor")
    print("Objetivo: Prever desconto >20% nos pr√≥ximos 30 dias")
    print("=" * 80)
    print()
    
    # Caminhos
    backend_root = Path(__file__).parent.parent  # pryzor-back/
    data_file = backend_root / "data" / "data_with_binary_target.csv"
    model_dir = backend_root / "ml_model"
    model_file = model_dir / "discount_predictor.pkl"
    
    print(f"üìÇ Backend root: {backend_root}")
    print(f"üìÑ Dataset: {data_file}")
    print(f"üíæ Modelo ser√° salvo em: {model_file}")
    print()
    
    # Verificar se dataset existe
    if not data_file.exists():
        print(f"‚ùå Erro: Dataset n√£o encontrado em {data_file}")
        print("   Execute primeiro: python scripts/prepare_binary_target.py")
        return
    
    # 1. Carregar dataset
    df_full = load_dataset(data_file)
    
    # 2. SPLIT TEMPORAL (CR√çTICO para s√©ries temporais!)
    print("‚úÇÔ∏è  DIVIDINDO DATASET COM VALIDA√á√ÉO TEMPORAL")
    print("-" * 80)
    print("‚ö†Ô∏è  IMPORTANTE: Usando split temporal (n√£o aleat√≥rio)")
    print("   Isso evita vazamento temporal (treino n√£o v√™ dados futuros)")
    print()
    
    # Converter coluna de data
    df_full['date'] = pd.to_datetime(df_full['date'])
    
    # Definir data de corte (70/30 aproximado)
    # Per√≠odo total: 2019-04-07 a 2020-07-13 (~15 meses)
    # Corte: 2020-04-01 (70% = ~10.5 meses treino, 30% = ~4.5 meses teste)
    cutoff_date = pd.to_datetime('2020-04-01')
    
    print(f"üìÖ Per√≠odo total: {df_full['date'].min().date()} a {df_full['date'].max().date()}")
    print(f"üìÖ Data de corte: {cutoff_date.date()}")
    print(f"   ‚îú‚îÄ Treino: antes de {cutoff_date.date()}")
    print(f"   ‚îî‚îÄ Teste:  a partir de {cutoff_date.date()}")
    print()
    
    # Criar m√°scaras temporais
    train_mask = df_full['date'] < cutoff_date
    test_mask = df_full['date'] >= cutoff_date
    
    df_train = df_full[train_mask].copy()
    df_test = df_full[test_mask].copy()
    
    print(f"   Treino: {len(df_train):>8,} amostras ({len(df_train)/len(df_full)*100:.1f}%)")
    print(f"   Teste:  {len(df_test):>8,} amostras ({len(df_test)/len(df_full)*100:.1f}%)")
    print()
    
    # 3. Preparar features de treino e teste separadamente
    print("üîß Preparando features de TREINO...")
    X_train, y_train, feature_names = prepare_features(df_train)
    
    print("üîß Preparando features de TESTE...")
    X_test, y_test, _ = prepare_features(df_test)
    
    print()
    
    # 4. Treinar modelo
    model = train_model(X_train, y_train)
    
    # 5. Avaliar modelo
    metrics = evaluate_model(model, X_test, y_test, feature_names)
    
    # 6. Salvar modelo
    save_model(model, feature_names, metrics, model_file)
    
    # 7. Decis√£o baseada em F1-Score
    print("=" * 80)
    print("RESUMO FINAL")
    print("=" * 80)
    print()
    
    f1 = metrics['f1_score']
    
    print(f"üéØ F1-Score obtido: {f1:.4f} ({f1*100:.2f}%)")
    print()
    
    # Interpreta√ß√£o do resultado
    if f1 >= 0.50:
        print("‚úÖ EXCELENTE! F1-Score ‚â• 0.50")
        print()
        print("üìå RECOMENDA√á√ÉO: Seguir PLANO A (Foco em ML)")
        print()
        print("Pr√≥ximos passos:")
        print("  1. Atualizar ml_model/evaluation_report.md com m√©tricas")
        print("  2. Integrar modelo na API (src/api/discount_service.py)")
        print("  3. Preparar slides focando em resultados de ML")
        print()
        print("Narrativa para TCC:")
        print("  'Modelo preditivo com m√©tricas s√≥lidas e aplic√°vel ao problema real.'")
    
    elif 0.40 <= f1 < 0.50:
        print("‚ö†Ô∏è  MODERADO. F1-Score entre 0.40 e 0.50")
        print()
        print("üìå RECOMENDA√á√ÉO: Seguir PLANO A.5 (H√≠brido)")
        print()
        print("Pr√≥ximos passos:")
        print("  1. Tentar melhorar features (adicionar hist√≥rico de 7/14 dias)")
        print("  2. Ajustar hiperpar√¢metros (GridSearch)")
        print("  3. Se n√£o melhorar: balancear ML + Engenharia na apresenta√ß√£o")
        print()
        print("Narrativa para TCC:")
        print("  'Modelo captura padr√µes, mas limitado por features dispon√≠veis.'")
    
    else:  # f1 < 0.40
        print("‚ùå BAIXO. F1-Score < 0.40")
        print()
        print("üìå RECOMENDA√á√ÉO: PIVOTAR para PLANO B (Foco em Engenharia)")
        print()
        print("Pr√≥ximos passos:")
        print("  1. Aceitar modelo como Proof of Concept")
        print("  2. Focar em arquitetura, pipeline ETL, engenharia de dados")
        print("  3. Preparar slides enfatizando processo, n√£o resultados")
        print()
        print("Narrativa para TCC:")
        print("  'Pipeline completo de ML em produ√ß√£o. Modelo valida metodologia,")
        print("   mas requer features externas (reviews, popularidade) para")
        print("   melhorar performance.'")
    
    print()
    print("=" * 80)
    print(f"‚úÖ Treinamento conclu√≠do! Modelo salvo em: {model_file}")
    print("=" * 80)


if __name__ == "__main__":
    main()
